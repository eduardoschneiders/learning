          From Wikipedia, the free encyclopedia                            Jump to:     navigation,      search          Interior point methods (also referred to as barrier methods) are a certain class of algorithms that solves linear and nonlinear convex optimization problems.     Example solution   John von Neumann[1] suggested an interior point method of linear programming which was neither a polynomial time method nor an efficient method in practice. In fact, it turned out to be slower in practice compared to simplex method which is not a polynomial time method. In 1984, Narendra Karmarkar developed a method for linear programming called Karmarkar's algorithm which runs in provably polynomial time and is also very efficient in practice. It enabled solutions of linear programming problems which were beyond the capabilities of the simplex method. Contrary to the simplex method, it reaches a best solution by traversing the interior of the feasible region. The method can be generalized to convex programming based on a self-concordant barrier function used to encode the convex set. Any convex optimization problem can be transformed into minimizing (or maximizing) a linear function over a convex set by converting to the epigraph form.[2] The idea of encoding the feasible set using a barrier and designing barrier methods was studied by Anthony V. Fiacco, Garth P. McCormick, and others in the early 1960s. These ideas were mainly developed for general nonlinear programming, but they were later abandoned due to the presence of more competitive methods for this class of problems (e.g. sequential quadratic programming). Yurii Nesterov and Arkadi Nemirovski came up with a special class of such barriers that can be used to encode any convex set. They guarantee that the number of iterations of the algorithm is bounded by a polynomial in the dimension and accuracy of the solution.[3] Karmarkar's breakthrough revitalized the study of interior point methods and barrier problems, showing that it was possible to create an algorithm for linear programming characterized by polynomial complexity and, moreover, that was competitive with the simplex method. Already Khachiyan's ellipsoid method was a polynomial time algorithm; however, it was too slow to be of practical interest. The class of primal-dual path-following interior point methods is considered the most successful. Mehrotra's predictor-corrector algorithm provides the basis for most implementations of this class of methods.[4]    Contents   1 Primal-dual interior point method for nonlinear optimization 2 See also 3 References 4 Bibliography    Primal-dual interior point method for nonlinear optimization[edit] The primal-dual method's idea is easy to demonstrate for constrained nonlinear optimization. For simplicity consider the all-inequality version of a nonlinear optimization problem:  minimize                         f         (         x         )                           {\displaystyle f(x)~}     subject to                                    c                        i                             (         x         )         ≥         0                                        for                            i         =         1         ,         …         ,         m         ,                             x         ∈                                 R                                   n                             ,                 {\displaystyle c_{i}(x)\geq 0~~{\text{for}}~i=1,\ldots ,m,~~x\in \mathbb {R} ^{n},}     where                         f         :                                 R                                   n                             →                    R                  ,                    c                        i                             :                                 R                                   n                             →                    R                                                                              (         1         )                 {\displaystyle f:\mathbb {R} ^{n}\rightarrow \mathbb {R} ,c_{i}:\mathbb {R} ^{n}\rightarrow \mathbb {R} ~~~~~~(1)}    .  The logarithmic barrier function associated with (1) is                          B         (         x         ,         μ         )         =         f         (         x         )         −         μ                              ∑                        i             =             1                                   m                             log         ⁡         (                    c                        i                             (         x         )         )                                                           (         2         )                 {\displaystyle B(x,\mu )=f(x)-\mu ~\sum _{i=1}^{m}\log(c_{i}(x))~~~~~(2)}      Here                         μ                 {\displaystyle \mu }     is a small positive scalar, sometimes called the "barrier parameter". As                         μ                 {\displaystyle \mu }     converges to zero the minimum of                         B         (         x         ,         μ         )                 {\displaystyle B(x,\mu )}     should converge to a solution of (1). The barrier function gradient is                                     g                        b                             =         g         −         μ                    ∑                        i             =             1                                   m                                                     1                                             c                                    i                                               (               x               )                                          ∇                    c                        i                             (         x         )                                                                     (         3         )                 {\displaystyle g_{b}=g-\mu \sum _{i=1}^{m}{\frac {1}{c_{i}(x)}}\nabla c_{i}(x)~~~~~~(3)}      where                         g                 {\displaystyle g}     is the gradient of the original function                         f         (         x         )                 {\displaystyle f(x)}     and                         ∇                    c                        i                                     {\displaystyle \nabla c_{i}}     is the gradient of                                    c                        i                                     {\displaystyle c_{i}}    . In addition to the original ("primal") variable                         x                 {\displaystyle x}     we introduce a Lagrange multiplier inspired dual variable                         λ         ∈                                 R                                   m                                     {\displaystyle \lambda \in \mathbb {R} ^{m}}                                         c                        i                             (         x         )                    λ                        i                             =         μ         ,         ∀         i         =         1         ,         …         ,         m                                                                               (         4         )                 {\displaystyle c_{i}(x)\lambda _{i}=\mu ,\forall i=1,\ldots ,m~~~~~~~(4)}      (4) is sometimes called the "perturbed complementarity" condition, for its resemblance to "complementary slackness" in KKT conditions. We try to find those                         (                    x                        μ                             ,                    λ                        μ                             )                 {\displaystyle (x_{\mu },\lambda _{\mu })}     for which the gradient of the barrier function is zero. Applying (4) to (3) we get an equation for the gradient:                          g         −                    A                        T                             λ         =         0                                                                     (         5         )                 {\displaystyle g-A^{T}\lambda =0~~~~~~(5)}      where the matrix                         A                 {\displaystyle A}     is the constraint                         c         (         x         )                 {\displaystyle c(x)}     Jacobian. The intuition behind (5) is that the gradient of                         f         (         x         )                 {\displaystyle f(x)}     should lie in the subspace spanned by the constraints' gradients. The "perturbed complementarity" with small                         μ                 {\displaystyle \mu }     (4) can be understood as the condition that the solution should either lie near the boundary                                    c                        i                             (         x         )         =         0                 {\displaystyle c_{i}(x)=0}     or that the projection of the gradient                         g                 {\displaystyle g}     on the constraint component                                    c                        i                             (         x         )                 {\displaystyle c_{i}(x)}     normal should be almost zero. Applying Newton's method to (4) and (5) we get an equation for                         (         x         ,         λ         )                 {\displaystyle (x,\lambda )}     update                         (                    p                        x                             ,                    p                        λ                             )                 {\displaystyle (p_{x},p_{\lambda })}    :                                                  (                                                                W                                                     −                                        A                                            T                                                                                                                           Λ                   A                                                     C                                                          )                                                     (                                                                                     p                                            x                                                                                                                                                p                                            λ                                                                                                  )                             =                                 (                                                                −                   g                   +                                        A                                            T                                                           λ                                                                                   μ                   1                   −                   C                   λ                                                          )                                     {\displaystyle {\begin{pmatrix}W&-A^{T}\\\Lambda A&C\end{pmatrix}}{\begin{pmatrix}p_{x}\\p_{\lambda }\end{pmatrix}}={\begin{pmatrix}-g+A^{T}\lambda \\\mu 1-C\lambda \end{pmatrix}}}      where                         W                 {\displaystyle W}     is the Hessian matrix of                         B         (         x         ,         μ         )                 {\displaystyle B(x,\mu )}     and                         Λ                 {\displaystyle \Lambda }     is a diagonal matrix of                         λ                 {\displaystyle \lambda }     and                         C                 {\displaystyle C}     is a diagonal matrix where                                    C                        i             i                                     {\displaystyle C_{ii}}     is                                    c                        i                             (         x         )                 {\displaystyle c_{i}(x)}    . Because of (1), (4) the condition                          λ         ≥         0                 {\displaystyle \lambda \geq 0}      should be enforced at each step. This can be done by choosing appropriate                         α                 {\displaystyle \alpha }    :                          (         x         ,         λ         )         →         (         x         +         α                    p                        x                             ,         λ         +         α                    p                        λ                             )                 {\displaystyle (x,\lambda )\rightarrow (x+\alpha p_{x},\lambda +\alpha p_{\lambda })}    .  See also[edit]  Augmented Lagrangian method Penalty method Karush–Kuhn–Tucker conditions  References[edit]   ^ Dantzig, George B.; Thapa, Mukund N. (2003). Linear Programming 2: Theory and Extensions. Springer-Verlag.  ^ Boyd, Stephen; Vandenberghe, Lieven (2004). Convex Optimization. Cambridge: Cambridge University Press. p. 143. ISBN 0-521-83378-7. MR 2061575.  ^ Wright, Margaret H. (2004). "The interior-point revolution in optimization: History, recent developments, and lasting consequences". Bulletin of the American Mathematical Society 42: 39. doi:10.1090/S0273-0979-04-01040-7. MR 2115066.  ^ Potra, Florian A.; Stephen J. Wright (2000). "Interior-point methods". Journal of Computational and Applied Mathematics 124 (1–2): 281–302. doi:10.1016/S0377-0427(00)00433-7.    Bibliography[edit]  Bonnans, J. Frédéric; Gilbert, J. Charles; Lemaréchal, Claude; Sagastizábal, Claudia A. (2006). Numerical optimization: Theoretical and practical aspects. Universitext (Second revised ed. of translation of 1997 French ed.). Berlin: Springer-Verlag. pp. xiv+490. doi:10.1007/978-3-540-35447-5. ISBN 3-540-35445-X. MR 2265882.  Karmarkar, N. (1984). "Proceedings of the sixteenth annual ACM symposium on Theory of computing - STOC '84" (PDF): 302. doi:10.1145/800057.808695. ISBN 0-89791-133-4.  |chapter= ignored (help) Mehrotra, Sanjay (1992). "On the Implementation of a Primal-Dual Interior Point Method". SIAM Journal on Optimization 2 (4): 575. doi:10.1137/0802028.  Nocedal, Jorge; Stephen Wright (1999). Numerical Optimization. New York, NY: Springer. ISBN 0-387-98793-2.  Press, WH; Teukolsky, SA; Vetterling, WT; Flannery, BP (2007). "Section 10.11. Linear Programming: Interior-Point Methods". Numerical Recipes: The Art of Scientific Computing (3rd ed.). New York: Cambridge University Press. ISBN 978-0-521-88068-8.  Wright, Stephen (1997). Primal-Dual Interior-Point Methods. Philadelphia, PA: SIAM. ISBN 0-89871-382-X.  Boyd, Stephen; Vandenberghe, Lieven (2004). Convex Optimization. Cambridge University Press.           v t e   Optimization: Algorithms, methods, and heuristics             Unconstrained nonlinear: Methods calling …           … functions    Golden section search Interpolation methods Line search Nelder–Mead method Successive parabolic interpolation         … and gradients     Convergence    Trust region Wolfe conditions         Quasi–Newton    BFGS and L-BFGS DFP Symmetric rank-one (SR1)         Other methods    Gauss–Newton Gradient Levenberg–Marquardt Conjugate gradient Truncated Newton            … and Hessians    Newton's method                          Constrained nonlinear           General    Barrier methods Penalty methods         Differentiable    Augmented Lagrangian methods Sequential quadratic programming Successive linear programming                     Convex optimization           Convex minimization    Cutting-plane method Reduced gradient (Frank–Wolfe) Subgradient method         Linear and quadratic     Interior point    Affine scaling Ellipsoid algorithm of Khachiyan Projective algorithm of Karmarkar         Basis-Exchange    Simplex algorithm of Dantzig Revised simplex algorithm Criss-cross algorithm Principal pivoting algorithm of Lemke                        Combinatorial           Paradigms    Approximation algorithm Dynamic programming Greedy algorithm Integer programming  Branch & bound or cut           Graph algorithms     Minimum spanning tree    Bellman–Ford Borůvka Dijkstra Floyd–Warshall Johnson Kruskal            Network flows    Dinic Edmonds–Karp Ford–Fulkerson Push–relabel maximum flow                     Metaheuristics          Evolutionary algorithm Hill climbing Local search Simulated annealing Tabu search               Categories  Algorithms and methods Heuristics   Software                            Retrieved from "https://en.wikipedia.org/w/index.php?title=Interior_point_method&oldid=702616046"          Categories: Optimization algorithms and methodsHidden categories: CS1 errors: chapter ignoredUse dmy dates from February 2011            
